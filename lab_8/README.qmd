---
 title: " Анализ данных сетевого трафика с использованием аналитической in-memory СУБД DuckDB"
 author: "odintsovajulia19@yandex.ru"
 format: 
   md:
     output-file: README.md
---

## Цель работы 

1. Изучить возможности СУБД DuckDB для обработки и анализ больших данных
2. Получить навыки применения DuckDB совместно с языком программирования R
3. Получить навыки анализа метаинфомации о сетевом трафике

## Исходные данные 
 
1. Программное обеспечение Windows 10 
2. Данные tm_data.pqt
2. Rstudio Desktop
3. Интерпретатор языка R 4.1
4. DuckDB и Dplyr.

## Задание

Используя язык программирования R, OLAP СУБД
DuckDB библиотеку duckdb и IDE Rstudio
Desktop, выполнить задания
и составить отчет.

## Ход работы

### Подготовим рабочую среду

```{r}
library(duckdb)
library(dplyr)
download.file("https://storage.yandexcloud.net/arrow-datasets/tm_data.pqt",destfile = "tm_data.pqt")
con <- dbConnect(duckdb())
dbExecute(con,"CREATE TABLE new_tbl as SELECT * FROM read_parquet('tm_data.pqt')")
```

### Задание 1: Надите утечку данных из Вашей сети

Важнейшие документы с результатами нашей исследовательской деятельности в
 области создания вакцин скачиваются в виде больших заархивированных дампов.
 Один из хостов в нашей сети используется для пересылки этой информации – он
 пересылает гораздо больше информации на внешние ресурсы в Интернете, чем
 остальные компьютеры нашей сети. Определите его IP-адрес.


```{r}
leak_1 = dbGetQuery(con,
"SELECT src FROM new_tbl
GROUP BY src
order by sum(bytes) desc
limit 1") 
print(leak_1)
```

### Задание 2: Надите утечку данных 2

Другой атакующий установил автоматическую задачу в системном планировщике
cron для экспорта содержимого внутренней wiki системы. Эта система генерирует
большое количество трафика в нерабочие часы, больше чем остальные хосты.
Определите IP этой системы. Известно, что ее IP адрес отличается от нарушителя из
предыдущей задачи.

```{r}
work_hours = dbGetQuery(con,
"SELECT hour, COUNT(*) AS work_hours
FROM (
    SELECT 
        timestamp,
        src,
        dst,
        bytes,
        EXTRACT(HOUR FROM epoch_ms(CAST(timestamp AS BIGINT))) AS hour
    FROM new_tbl
) sub
WHERE hour BETWEEN 0 AND 24
GROUP BY hour
ORDER BY work_hours DESC;") 
print(work_hours)
```
 
- Понимаем, что для поиска будет использоваться временной интервал 0 - 15
 
```{r}
leak_2 = dbGetQuery(con,
"SELECT src
FROM (
    SELECT src, SUM(bytes) AS trafic
    FROM (
        SELECT *,
            EXTRACT(HOUR FROM epoch_ms(CAST(timestamp AS BIGINT))) AS hour
        FROM new_tbl
    ) sub
    WHERE src <> '13.37.84.125' AND hour BETWEEN 1 AND 15
    GROUP BY src
) grp
ORDER BY trafic DESC
LIMIT 1;") 
print(leak_2)
```
 
### Задание 3: Надите утечку данных 3
 
Еще один нарушитель собирает содержимое электронной почты и отправляет в
Интернет используя порт, который обычно используется для другого типа трафика.
Атакующий пересылает большое количество информации используя этот порт,
которое нехарактерно для других хостов, использующих этот номер порта.
Определите IP этой системы. Известно, что ее IP адрес отличается от нарушителей
из предыдущих задач.
 
```{r}
exclude_hosts = dbExecute(con,
"CREATE TEMPORARY TABLE exclude_hosts AS
SELECT src, bytes, port
FROM new_tbl
WHERE src <> '13.37.84.125'
    AND src <> '12.55.77.96';")

unsafe_ports = dbGetQuery(con,
"SELECT port, AVG(bytes) AS mean_bytes, 
MAX(bytes) AS max_bytes, 
SUM(bytes) AS sum_bytes, 
MAX(bytes) - AVG(bytes) AS diff
FROM exclude_hosts
GROUP BY port
HAVING diff != 0
ORDER BY diff DESC
LIMIT 1;") 
print(unsafe_ports)
```
 
- Пришли к выводу, что порт 119 наиболее вероятно используется нарушителем. Посмотрим информацию о нем
 
```{r}
leak_3 = dbGetQuery(con,"SELECT src
FROM (
    SELECT src, AVG(bytes) AS mean
    FROM exclude_hosts
    WHERE port = 119
    GROUP BY src
) AS leak_3
ORDER BY mean DESC
LIMIT 1;") 
print(leak_3)
```

## Оценка результата

С использованием инструментов DuckDB и RStudio Server были проведены задания по исследованию сетевого трафика.

## Вывод 

Провели работу с DuckDB, ознакомились с применением облачных технологий для хранения, подготовки и анализа данных, а также проанализировали метаинформацию о сетевом трафике.
 